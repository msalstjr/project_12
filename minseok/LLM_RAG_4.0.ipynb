{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b24e64",
   "metadata": {},
   "source": [
    "### ë¼ì´ë¸ŒëŸ¬ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73575ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain import hub\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d5e8a",
   "metadata": {},
   "source": [
    "### API í‚¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a98cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# API í‚¤ ì„¤ì •\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "OPENAI_API_KEY    = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a12359",
   "metadata": {},
   "source": [
    "### PDF ë¡œë“œ / ì„ë² ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2933a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KDT2\\AppData\\Local\\Temp\\ipykernel_8856\\98390258.py:10: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\",\n"
     ]
    }
   ],
   "source": [
    "# PDF ë¡œë“œ ë° ë¶„í• \n",
    "loader = PyPDFLoader(\"KB ì‹¤ë²„ì•” ê°„í¸ê±´ê°•ë³´í—˜Plus.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size    = 200, \n",
    "                                               chunk_overlap = 20,\n",
    "                                               )\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "# OpenAI ì„ë² ë”©\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\",\n",
    "                              openai_api_key = OPENAI_API_KEY,\n",
    "                              )\n",
    "\n",
    "# FAISS ë²¡í„° ì €ì¥ì†Œ\n",
    "vectorstore = FAISS.from_documents(docs, \n",
    "                                   embedding=embeddings,\n",
    "                                   )\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "febdb73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KDT2\\AppData\\Roaming\\Python\\Python311\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¾ ì§ˆë¬¸: ë³´í—˜ê¸ˆì²­êµ¬ í–ˆëŠ”ë° ì–¸ì œ ì§€ê¸‰ë˜ë‹ˆ?\n",
      "\n",
      "ğŸ’¬ [LLM ë‹¨ë… ì‘ë‹µ]:\n",
      "content='ë³´í—˜ê¸ˆ ì§€ê¸‰ ì‹œê¸°ëŠ” ë³´í—˜ì‚¬ì™€ ì²­êµ¬ ë‚´ìš©ì— ë”°ë¼ ë‹¤ë¥´ì§€ë§Œ, ì¼ë°˜ì ì¸ ê¸°ì¤€ì„ ì•ˆë‚´í•´ë“œë¦´ê²Œìš”.\\n\\n**ì¼ë°˜ì ì¸ ì²˜ë¦¬ ê¸°ê°„:**\\n- **ë‹¨ìˆœ ì²­êµ¬**: ì„œë¥˜ ì ‘ìˆ˜ í›„ 3~7ì˜ì—…ì¼\\n- **ë³µì¡í•œ ì²­êµ¬**: 10~30ì¼ (ì¡°ì‚¬ê°€ í•„ìš”í•œ ê²½ìš°)\\n\\n**í™•ì¸í•˜ì‹¤ ì‚¬í•­:**\\n1. **ì„œë¥˜ ì™„ë¹„ ì—¬ë¶€** - ëˆ„ë½ëœ ì„œë¥˜ê°€ ìˆìœ¼ë©´ ì§€ì—°ë©ë‹ˆë‹¤\\n2. **ë³´í—˜ì‚¬ ì‹¬ì‚¬ ì§„í–‰ ìƒí™©** - ê³ ê°ì„¼í„°ë‚˜ ì•±ì—ì„œ í™•ì¸ ê°€ëŠ¥\\n3. **ì¶”ê°€ ì„œë¥˜ ìš”ì²­** - ë¬¸ìë‚˜ ì „í™” í™•ì¸\\n\\n**ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ íŒ:**\\n- ë³´í—˜ì‚¬ ê³ ê°ì„¼í„°ì— ì§ì ‘ ë¬¸ì˜\\n- ëª¨ë°”ì¼ ì•±ì—ì„œ ì§„í–‰ìƒí™© í™•ì¸\\n- ë‹´ë‹¹ì ì—°ë½ì²˜ í™•ë³´\\n\\nì •í™•í•œ ì¼ì •ì€ ê°€ì…í•˜ì‹  ë³´í—˜ì‚¬ì— ì§ì ‘ ë¬¸ì˜í•˜ì‹œëŠ” ê²ƒì´ ê°€ì¥ í™•ì‹¤í•©ë‹ˆë‹¤. ë³´í—˜ì‚¬ëª…ê³¼ ì²­êµ¬ë²ˆí˜¸ë¥¼ ì¤€ë¹„í•˜ì‹œë©´ ë” ë¹ ë¥¸ í™•ì¸ì´ ê°€ëŠ¥í•´ìš”.' additional_kwargs={} response_metadata={'id': 'msg_01BD6vT5wUHj3QZtYJsKx8CD', 'model': 'claude-opus-4-20250514', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 26, 'output_tokens': 362, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-opus-4-20250514'} id='run--29d59e59-0bb6-4eee-b52b-91f7d1c98efc-0' usage_metadata={'input_tokens': 26, 'output_tokens': 362, 'total_tokens': 388, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}\n",
      "\n",
      "ğŸ“š [RAG ê¸°ë°˜ ì‘ë‹µ]:\n",
      "ë³´í—˜ê¸ˆì€ ì²­êµ¬ì„œë¥˜ ì ‘ìˆ˜ì¼ë¶€í„° 3ì˜ì—…ì¼ ì´ë‚´ì— ì§€ê¸‰ë©ë‹ˆë‹¤. ë‹¤ë§Œ, ì†í•´ì‚¬ì •ì´ë‚˜ ì¡°ì‚¬ ë“±ì´ í•„ìš”í•œ ê²½ìš°ì—ëŠ” ìµœëŒ€ 30ì˜ì—…ì¼ê¹Œì§€ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# Claude LLM\n",
    "llm = ChatAnthropic(model=\"claude-opus-4-20250514\",\n",
    "                    temperature=0,\n",
    "                    max_tokens=1024,\n",
    "                    api_key=ANTHROPIC_API_KEY,\n",
    "                    )\n",
    "\n",
    "# RAG í”„ë¡¬í”„íŠ¸\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# RAG ì²´ì¸ êµ¬ì„±\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ì§ˆë¬¸\n",
    "# question = \"ê³ ì§€ì˜ë¬´ë¥¼ ìœ„ë°˜í•œ ê²½ìš° ë³´í—˜ì‚¬ëŠ” ì–´ë–¤ ì¡°ì¹˜ë¥¼ ì·¨í•  ìˆ˜ ìˆë‚˜ìš”?\"                                  # ë¯¼ì„ ì§ˆë¬¸\n",
    "# question = \"íŠ¹ì •ì•” iië€ ë­ì•¼?\"                                                                          # 1ë²ˆ ì§ˆë¬¸\n",
    "# question = \"ìœ ì‚¬ì•”ì§„ë‹¨ë¹„iii ë¥¼ ì²­êµ¬í•˜ë ¤ê³  í•˜ëŠ”ë° ê°‘ìƒì„ ì•”ì€ ì–´ë–¤ ê²€ì‚¬ë¥¼ í†µí•´ ì§„ë‹¨ë°›ì•„ì•¼ë¼?\"                # 2ë²ˆ ì§ˆë¬¸\n",
    "# question = \"í†µí•©ì•”ì§„ë‹¨ë¹„ii ëŠ” ë³´ì¥ë²”ìœ„ê°€ ì–´ë–»ê²Œ ë¼?\"                                                      # 3ë²ˆ ì§ˆë¬¸\n",
    "# question = \"í†µí•©ì „ì´ì•”ì§„ë‹¨ë¹„ì˜ ë³´ì¥ë²”ìœ„ëŠ” ì–´ë–»ê²Œ ë¼?\"                                                     # 4ë²ˆ ì§ˆë¬¸\n",
    "# question = \"ë³´í•¨ê³„ì•½í•œì§€ 8ê°œì›”ì´ ì§€ë‚¬ëŠ”ë° í‘œì í•­ì•”ë°©ì‚¬ì„  ì¹˜ë£Œë¹„ë¥¼ ë³´í—˜ê°€ì…ê¸ˆì•¡ì˜ 100%ë¥¼ ë°›ì„ ìˆ˜ ìˆì–´?\"      # 5ë²ˆ ì§ˆë¬¸\n",
    "# question = \"ì‹ ì¬ì§„ë‹¨ì•”ì§„ë‹¨ë¹„ii ì—ì„œ ìˆ˜ìˆ ì´ë€ ë­ì•¼?\"                                                       # 6ë²ˆ ì§ˆë¬¸    \n",
    "question = \"ë³´í—˜ê¸ˆì²­êµ¬ í–ˆëŠ”ë° ì–¸ì œ ì§€ê¸‰ë˜ë‹ˆ?\"                                                             # 7ë²ˆ ì§ˆë¬¸\n",
    "\n",
    "# 1. RAG ê¸°ë°˜ ì‘ë‹µ\n",
    "rag_answer = rag_chain.invoke(question)\n",
    "\n",
    "# 2. ìˆœìˆ˜ LLM ì‘ë‹µ (ë¬¸ì„œ ì—†ì´ ë°”ë¡œ Claudeì—ê²Œ ì§ˆë¬¸)\n",
    "llm_only_answer = llm.invoke(question)\n",
    "\n",
    "# ì¶œë ¥\n",
    "print(\"ğŸ§¾ ì§ˆë¬¸:\", question)\n",
    "print(\"\\nğŸ’¬ [LLM ë‹¨ë… ì‘ë‹µ]:\")\n",
    "print(llm_only_answer)\n",
    "print(\"\\nğŸ“š [RAG ê¸°ë°˜ ì‘ë‹µ]:\")\n",
    "print(rag_answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789bcbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec35343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
