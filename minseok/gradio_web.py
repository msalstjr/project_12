import os
import shutil
import gradio as gr
from typing import List, Tuple
from langchain.document_loaders import PyPDFLoader
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings   # ìˆ˜ì •!
from langchain_anthropic import ChatAnthropic
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain import hub
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")

VECTOR_ROOT = "vectorstores"
UPLOAD_DIR = "uploaded_pdfs"
os.makedirs(VECTOR_ROOT, exist_ok=True)
os.makedirs(UPLOAD_DIR, exist_ok=True)

uploaded_files = []
built_categories = set()

category_keywords = {
    "ì•”ë³´í—˜": ["ì•”"],
    "ì‹¤ë¹„ë³´í—˜": ["ì‹¤ì†"],
    "ìƒí•´ë³´í—˜": ["ìƒí•´"],
    "í™”ì¬ë³´í—˜": ["í™”ì¬"]
}

def get_category_from_filename(filename):
    for category, keywords in category_keywords.items():
        if any(keyword in filename for keyword in keywords):
            return category
    return "ì•”ë³´í—˜"  # fallback

text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)
embedding = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=OPENAI_API_KEY)

def upload_pdf(file, file_list):
    filename = os.path.basename(file.name)
    save_path = os.path.join(UPLOAD_DIR, filename)
    shutil.copy(file.name, save_path)
    if save_path not in file_list:
        file_list.append(save_path)
    # íŒŒì¼ ì´ë¦„ë§Œ ì¶”ì¶œí•˜ì—¬ í•œ ì¤„ì”© ë³´ì—¬ì£¼ê¸°
    all_filenames = [os.path.basename(f) for f in file_list]
    return file_list, "\n".join(all_filenames)

def build_vectorstores(file_list):
    global built_categories
    built_categories.clear()
    for path in file_list:
        filename = os.path.basename(path)
        category = get_category_from_filename(filename)
        print(f"[+] Building vectorstore for: {filename} â†’ category={category}")

        loader = PyPDFLoader(path)
        pages = loader.load_and_split()
        docs = text_splitter.split_documents(pages)

        vectorstore_path = os.path.join(VECTOR_ROOT, category)
        if os.path.exists(vectorstore_path):
            shutil.rmtree(vectorstore_path)
        vectorstore = FAISS.from_documents(docs, embedding=embedding)
        vectorstore.save_local(vectorstore_path)
        built_categories.add(category)

    return f"ğŸ“š ì´ {len(built_categories)}ê°œ ì¹´í…Œê³ ë¦¬ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ: {', '.join(built_categories)}"

category_keywords_full = {
    "ì•”ë³´í—˜": [
        "ì•”", "ìœ ì‚¬ì•”", "íŠ¹ì •ì•”", "ì „ì´ì•”", "ì¬ì§„ë‹¨ì•”", "ê°‘ìƒì„ ì•”", "íì•”", "ê°„ì•”", "ì·Œì¥ì•”",
        "ì†Œí™”ê¸°ê´€ì•”", "í˜ˆì•¡ì•”", "ìƒì‹ê¸°ì•”", "í•­ì•”", "í•­ì•”ì¹˜ë£Œ", "ë°©ì‚¬ì„ ì¹˜ë£Œ", "í•­ì•”ë°©ì‚¬ì„ ",
        "í•­ì•”ì•½ë¬¼", "í‘œì í•­ì•”", "í˜¸ë¥´ëª¬ì•½ë¬¼", "CAR-T", "ì§„ë‹¨ë¹„", "ì•”ì§„ë‹¨ë¹„", "ì•”ì‚¬ë§"
    ],
    "ì‹¤ë¹„ë³´í—˜": [
        "ì‹¤ì†", "ì˜ë£Œë¹„", "ì…ì›", "í†µì›", "ì§„ë£Œë¹„", "ê²€ì‚¬ë¹„", "ìˆ˜ìˆ ", "ì‘ê¸‰ì‹¤", "ì¹˜ë£Œ",
        "ìê¸°ë¶€ë‹´ê¸ˆ", "ë³´í—˜ê¸ˆ í•œë„", "ì§„ë‹¨ì„œ", "ì˜ë¬´ê¸°ë¡", "ë³´ìƒì¢…ëª©", "ë‹¤ìˆ˜ë³´í—˜", "ì—°ëŒ€ì±…ì„"
    ],
    "ìƒí•´ë³´í—˜": [
        "ìƒí•´", "ì¬í•´", "ì‚¬ê³ ", "êµí†µì‚¬ê³ ", "ê³¨ì ˆ", "í™”ìƒ", "í›„ìœ ì¥í•´", "ì‚¬ê³ ì‚¬ë§",
        "ì…ì›ë¹„", "ìˆ˜ìˆ ë¹„", "ìƒí•´ì‚¬ë§", "ìƒí•´íŠ¹ì•½"
    ],
    "í™”ì¬ë³´í—˜": [
        "í™”ì¬", "í­ë°œ", "ë¶•ê´´", "ëˆ„ìˆ˜", "ë„ë‚œ", "ë°°ìƒì±…ì„", "ì¬ì‚°", "ê°€ì¬ë„êµ¬",
        "ë³µêµ¬", "ì†í•´", "í”¼í•´", "ì£¼íƒ", "í™”ì¬ë³´í—˜", "í™”ì¬ì‚¬ê³ "
    ]
}

def classify_question(question):
    for category, keywords in category_keywords_full.items():
        if any(keyword in question for keyword in keywords):
            return category
    return "cancer"

llm = ChatAnthropic(model="claude-opus-4-20250514", temperature=0, max_tokens=1024, api_key=ANTHROPIC_API_KEY)
prompt = hub.pull("rlm/rag-prompt")
llm_only_chain = llm | StrOutputParser()

def answer_question(question, chat_history):
    category = classify_question(question)
    vectorstore_path = os.path.join(VECTOR_ROOT, category)

    if not os.path.exists(vectorstore_path):
        msg = f"âŒ ì„ íƒëœ ì¹´í…Œê³ ë¦¬ '{category}'ì˜ ë²¡í„°ìŠ¤í† ì–´ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € ê´€ë ¨ PDFë¥¼ ì—…ë¡œë“œí•˜ê³  ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•˜ì„¸ìš”."
        chat_history.append((question, msg))
        return chat_history

    vectorstore = FAISS.load_local(vectorstore_path, embeddings=embedding, allow_dangerous_deserialization=True)
    retriever = vectorstore.as_retriever()

    rag_chain = ( {"context": retriever, "question": RunnablePassthrough()} | prompt | llm | StrOutputParser() )
    rag_answer = rag_chain.invoke(question)

    # RAG ë‹µë³€ë§Œ!
    combined = f"[ğŸ“‚ ì„ íƒëœ ì¹´í…Œê³ ë¦¬: {category}]\n\n"
    combined += f"ğŸ“š RAG ê¸°ë°˜ ì‘ë‹µ:\n{rag_answer}"
    chat_history.append((question, combined))
    return chat_history


# Gradio UI
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("## ğŸ“„ ë³´í—˜ì•½ê´€ RAG ì‹œìŠ¤í…œ")

    # ì—…ë¡œë“œ ì˜ì—­
    with gr.Row():
        file_input = gr.File(label="PDF ì—…ë¡œë“œ", file_types=[".pdf"], file_count="single")
        upload_btn = gr.Button("ğŸ“¥ PDF ì¶”ê°€")
    upload_status = gr.Textbox(label="ì—…ë¡œë“œëœ PDF ëª©ë¡", interactive=False)

    # ìƒíƒœ ê´€ë¦¬ ë³€ìˆ˜ (hidden)
    state_files = gr.State([])
    state_chat = gr.State([])

    confirm_btn = gr.Button("âœ… PDF ì—…ë¡œë“œ ì™„ë£Œ & ë²¡í„°ìŠ¤í† ì–´ ìƒì„±")
    confirm_output = gr.Textbox(label="ìƒì„± ìƒíƒœ", interactive=False)

    gr.Markdown("### ğŸ’¬ ë³´í—˜ ì•½ê´€ ì±—ë´‡ (Chat RAG)")

    with gr.Row():
        # ì±„íŒ…ë°•ìŠ¤ (ì™¼ìª½: ë‹µë³€, ì˜¤ë¥¸ìª½: ì§ˆë¬¸)
        chatbot = gr.Chatbot(label="ì±—ë´‡ ëŒ€í™” ë‚´ì—­", height=400, show_copy_button=True, avatar_images=(None, None))

    chat_input = gr.Textbox(label="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ê¶ê¸ˆí•œ ì ì„ ì…ë ¥ í›„ Enter", lines=1)

    # ë²„íŠ¼ í´ë¦­/ì…ë ¥ì‹œ ë™ì‘
    upload_btn.click(
        upload_pdf, 
        inputs=[file_input, state_files], 
        outputs=[state_files, upload_status]
    )
    confirm_btn.click(
        build_vectorstores,
        inputs=[state_files],
        outputs=[confirm_output]
    )
    chat_input.submit(
        answer_question,
        inputs=[chat_input, state_chat],
        outputs=[chatbot],
        queue=True
    ).then(
        lambda chat_input, chat_history: ("", chat_history), # ì…ë ¥ì°½ ì´ˆê¸°í™”
        inputs=[chat_input, state_chat],
        outputs=[chat_input, state_chat]
    )

demo.queue()  # ë°˜ë“œì‹œ ì¶”ê°€!!
demo.launch()

