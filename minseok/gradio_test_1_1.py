import os
import shutil
import gradio as gr
from typing import List
from langchain.document_loaders import PyPDFLoader
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain_anthropic import ChatAnthropic
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain import hub
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")

# ê²½ë¡œ ì„¤ì •
VECTOR_ROOT = "vectorstores"
UPLOAD_DIR = "uploaded_pdfs"
os.makedirs(VECTOR_ROOT, exist_ok=True)
os.makedirs(UPLOAD_DIR, exist_ok=True)

# ì „ì—­ ìƒíƒœ
uploaded_files = []
built_categories = set()

# ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
category_keywords = {
    "cancer": ["ì•”"],
    "medical": ["ì‹¤ì†"],
    "accident": ["ìƒí•´"],
    "fire": ["í™”ì¬"]
}

def get_category_from_filename(filename):
    for category, keywords in category_keywords.items():
        if any(keyword in filename for keyword in keywords):
            return category
    return "cancer"  # ê¸°ë³¸ fallback

# í…ìŠ¤íŠ¸ ë¶„í• ê¸° / ì„ë² ë”© ëª¨ë¸
text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)
embedding = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=OPENAI_API_KEY)

# PDF ì—…ë¡œë“œ ì²˜ë¦¬
def upload_pdf(file):
    filename = os.path.basename(file.name)
    save_path = os.path.join(UPLOAD_DIR, filename)
    shutil.copy(file.name, save_path)
    uploaded_files.append(save_path)
    return f"âœ… '{filename}' ì—…ë¡œë“œ ì™„ë£Œ. ë” ì—…ë¡œë“œí•  íŒŒì¼ì´ ìˆë‚˜ìš”?"

# ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
def build_vectorstores():
    global built_categories
    built_categories.clear()
    for path in uploaded_files:
        filename = os.path.basename(path)
        category = get_category_from_filename(filename)
        print(f"[+] Building vectorstore for: {filename} â†’ category={category}")

        loader = PyPDFLoader(path)
        pages = loader.load_and_split()
        docs = text_splitter.split_documents(pages)

        vectorstore_path = os.path.join(VECTOR_ROOT, category)
        if os.path.exists(vectorstore_path):
            shutil.rmtree(vectorstore_path)
        vectorstore = FAISS.from_documents(docs, embedding=embedding)
        vectorstore.save_local(vectorstore_path)
        built_categories.add(category)

    return f"ğŸ“š ì´ {len(built_categories)}ê°œ ì¹´í…Œê³ ë¦¬ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ: {', '.join(built_categories)}"

# ì§ˆë¬¸ â†’ ì¹´í…Œê³ ë¦¬ ì¶”ë¡ 
category_keywords_full = {
    "cancer": [
        "ì•”", "ìœ ì‚¬ì•”", "íŠ¹ì •ì•”", "ì „ì´ì•”", "ì¬ì§„ë‹¨ì•”", "ê°‘ìƒì„ ì•”", "íì•”", "ê°„ì•”", "ì·Œì¥ì•”",
        "ì†Œí™”ê¸°ê´€ì•”", "í˜ˆì•¡ì•”", "ìƒì‹ê¸°ì•”", "í•­ì•”", "í•­ì•”ì¹˜ë£Œ", "ë°©ì‚¬ì„ ì¹˜ë£Œ", "í•­ì•”ë°©ì‚¬ì„ ",
        "í•­ì•”ì•½ë¬¼", "í‘œì í•­ì•”", "í˜¸ë¥´ëª¬ì•½ë¬¼", "CAR-T", "ì§„ë‹¨ë¹„", "ì•”ì§„ë‹¨ë¹„", "ì•”ì‚¬ë§"
    ],
    "medical": [
        "ì‹¤ì†", "ì˜ë£Œë¹„", "ì…ì›", "í†µì›", "ì§„ë£Œë¹„", "ê²€ì‚¬ë¹„", "ìˆ˜ìˆ ", "ì‘ê¸‰ì‹¤", "ì¹˜ë£Œ",
        "ìê¸°ë¶€ë‹´ê¸ˆ", "ë³´í—˜ê¸ˆ í•œë„", "ì§„ë‹¨ì„œ", "ì˜ë¬´ê¸°ë¡", "ë³´ìƒì¢…ëª©", "ë‹¤ìˆ˜ë³´í—˜", "ì—°ëŒ€ì±…ì„"
    ],
    "accident": [
        "ìƒí•´", "ì¬í•´", "ì‚¬ê³ ", "êµí†µì‚¬ê³ ", "ê³¨ì ˆ", "í™”ìƒ", "í›„ìœ ì¥í•´", "ì‚¬ê³ ì‚¬ë§",
        "ì…ì›ë¹„", "ìˆ˜ìˆ ë¹„", "ìƒí•´ì‚¬ë§", "ìƒí•´íŠ¹ì•½"
    ],
    "fire": [
        "í™”ì¬", "í­ë°œ", "ë¶•ê´´", "ëˆ„ìˆ˜", "ë„ë‚œ", "ë°°ìƒì±…ì„", "ì¬ì‚°", "ê°€ì¬ë„êµ¬",
        "ë³µêµ¬", "ì†í•´", "í”¼í•´", "ì£¼íƒ", "í™”ì¬ë³´í—˜", "í™”ì¬ì‚¬ê³ "
    ]
}

def classify_question(question):
    for category, keywords in category_keywords_full.items():
        if any(keyword in question for keyword in keywords):
            return category
    return "cancer"

# LLM & RAG êµ¬ì„±
llm = ChatAnthropic(model="claude-opus-4-20250514", temperature=0, max_tokens=1024, api_key=ANTHROPIC_API_KEY)
prompt = hub.pull("rlm/rag-prompt")
llm_only_chain = llm | StrOutputParser()

def answer_question(question):
    category = classify_question(question)
    vectorstore_path = os.path.join(VECTOR_ROOT, category)

    if not os.path.exists(vectorstore_path):
        return f"âŒ ì„ íƒëœ ì¹´í…Œê³ ë¦¬ '{category}'ì˜ ë²¡í„°ìŠ¤í† ì–´ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € ê´€ë ¨ PDFë¥¼ ì—…ë¡œë“œí•˜ê³  ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•˜ì„¸ìš”."

    vectorstore = FAISS.load_local(vectorstore_path, embeddings=embedding, allow_dangerous_deserialization=True)
    retriever = vectorstore.as_retriever()

    rag_chain = ( {"context": retriever, "question": RunnablePassthrough()} | prompt | llm | StrOutputParser() )

    llm_answer = llm_only_chain.invoke(question)
    rag_answer = rag_chain.invoke(question)

    result = f"[ğŸ“‚ ì„ íƒëœ ì¹´í…Œê³ ë¦¬: {category}]\n\n"
    result += f"ğŸ’¬ LLM ë‹¨ë… ì‘ë‹µ:\n{llm_answer}\n\n"
    result += f"ğŸ“š RAG ê¸°ë°˜ ì‘ë‹µ:\n{rag_answer}"
    return result

# Gradio UI
with gr.Blocks() as demo:
    gr.Markdown("## ğŸ“„ ë³´í—˜ì•½ê´€ RAG ì‹œìŠ¤í…œ")

    with gr.Row():
        file_input = gr.File(label="PDF ì—…ë¡œë“œ", file_types=[".pdf"], file_count="single")
        upload_btn = gr.Button("ğŸ“¥ PDF ì¶”ê°€")
    upload_output = gr.Textbox(label="ì—…ë¡œë“œ ìƒíƒœ")

    confirm_btn = gr.Button("âœ… PDF ì—…ë¡œë“œ ì™„ë£Œ & ë²¡í„°ìŠ¤í† ì–´ ìƒì„±")
    confirm_output = gr.Textbox(label="ìƒì„± ìƒíƒœ")

    question_input = gr.Textbox(label="ì§ˆë¬¸ ì…ë ¥")
    question_btn = gr.Button("ğŸ” ì§ˆë¬¸í•˜ê¸°")
    answer_output = gr.Textbox(label="ë‹µë³€ ì¶œë ¥", lines=10)

    upload_btn.click(upload_pdf, inputs=[file_input], outputs=[upload_output])
    confirm_btn.click(build_vectorstores, outputs=[confirm_output])
    question_btn.click(answer_question, inputs=[question_input], outputs=[answer_output])

demo.launch()

