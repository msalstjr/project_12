{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d14f41e7",
   "metadata": {},
   "source": [
    "### ë¼ì´ë¸ŒëŸ¬ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153eae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc65a14",
   "metadata": {},
   "source": [
    "### API í‚¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "583ec5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "OPENAI_API_KEY    = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1830569",
   "metadata": {},
   "source": [
    "### ì¢Œìš° í…ìŠ¤íŠ¸ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11cc3645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: KB_ì‹¤ë²„ì•”_ê°„í¸ê±´ê°•ë³´í—˜Plus.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KDT2\\AppData\\Local\\Temp\\ipykernel_7684\\253296897.py:58: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\",\n",
      "C:\\Users\\KDT2\\AppData\\Roaming\\Python\\Python311\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# âœ… 1. PDF â†’ ì¢Œ/ìš° í…ìŠ¤íŠ¸ ì¶”ì¶œ â†’ TXT ì €ì¥\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def extract_left_right_text(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    left_text_total = \"\"\n",
    "    right_text_total = \"\"\n",
    "\n",
    "    for page_num, page in enumerate(doc):\n",
    "        width = page.rect.width\n",
    "        blocks = page.get_text(\"blocks\")\n",
    "\n",
    "        left_text = \"\"\n",
    "        right_text = \"\"\n",
    "\n",
    "        for b in blocks:\n",
    "            x0, y0, x1, y1, text, *_ = b\n",
    "            center_x = (x0 + x1) / 2\n",
    "            if center_x < width / 2:\n",
    "                left_text += text.strip() + \" \"\n",
    "            else:\n",
    "                right_text += text.strip() + \" \"\n",
    "\n",
    "        left_text_total += f\"[í˜ì´ì§€ {page_num + 1} - ì¢Œ]\\n{left_text.strip()}\\n\\n\"\n",
    "        right_text_total += f\"[í˜ì´ì§€ {page_num + 1} - ìš°]\\n{right_text.strip()}\\n\\n\"\n",
    "\n",
    "    return left_text_total + right_text_total  # â¬…ï¸ í•©ì³ì„œ ë°˜í™˜\n",
    "\n",
    "\n",
    "# ğŸ”¹ PDF ê²½ë¡œ ë° TXT ì €ì¥\n",
    "pdf_path = \"KB ì‹¤ë²„ì•” ê°„í¸ê±´ê°•ë³´í—˜Plus.pdf\"\n",
    "txt_path = \"KB_ì‹¤ë²„ì•”_ê°„í¸ê±´ê°•ë³´í—˜Plus.txt\"\n",
    "\n",
    "if not os.path.exists(txt_path):\n",
    "    full_text = extract_left_right_text(pdf_path)\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(full_text)\n",
    "    print(f\"âœ… í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {txt_path}\")\n",
    "else:\n",
    "    print(f\"ğŸ“„ ê¸°ì¡´ í…ìŠ¤íŠ¸ íŒŒì¼ ì‚¬ìš©: {txt_path}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# âœ… 2. LangChain RAG íŒŒì´í”„ë¼ì¸\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# ğŸ“„ TXT ë¡œë“œ ë° ë¶„í• \n",
    "loader = TextLoader(txt_path, encoding=\"utf-8\")\n",
    "docs_raw = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, \n",
    "                                               chunk_overlap=50,\n",
    "                                               )\n",
    "docs = text_splitter.split_documents(docs_raw)\n",
    "\n",
    "# ğŸ§  ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", \n",
    "                              openai_api_key=OPENAI_API_KEY,\n",
    "                              )\n",
    "vectorstore = FAISS.from_documents(docs, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# ğŸ¤– Claude LLM\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-opus-4-20250514\",\n",
    "    temperature=0,\n",
    "    max_tokens=1024,\n",
    "    api_key=ANTHROPIC_API_KEY,\n",
    ")\n",
    "\n",
    "# ğŸ§© RAG í”„ë¡¬í”„íŠ¸ + ì²´ì¸ êµ¬ì„±\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "llm_only_chain = llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbffbc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¾ ì§ˆë¬¸: í†µí•©ì „ì´ì•”ì§„ë‹¨ë¹„ì˜ ë³´ì¥ì˜ë²”ìœ„ëŠ” ì–´ë–»ê²Œ ë¼?\n",
      "\n",
      "ğŸ’¬ [LLM ë‹¨ë… ì‘ë‹µ]:\n",
      "í†µí•©ì „ì´ì•”ì§„ë‹¨ë¹„ì˜ ë³´ì¥ë²”ìœ„ì— ëŒ€í•´ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "## í†µí•©ì „ì´ì•”ì§„ë‹¨ë¹„ ë³´ì¥ë²”ìœ„\n",
      "\n",
      "### 1. **ê¸°ë³¸ ë³´ì¥ë‚´ìš©**\n",
      "- ì›ë°œì•”ê³¼ ë‹¤ë¥¸ ì¥ê¸°ë¡œ ì•”ì´ ì „ì´ëœ ê²½ìš°\n",
      "- ìµœì´ˆ 1íšŒì— í•œí•´ ì§„ë‹¨ë¹„ ì§€ê¸‰\n",
      "- ì›ë°œì•” ì§„ë‹¨ ì´í›„ ì „ì´ì•” ì§„ë‹¨ ì‹œ ë³´ì¥\n",
      "\n",
      "### 2. **ì£¼ìš” ë³´ì¥ ì¡°ê±´**\n",
      "- **ì›ê²©ì „ì´**: ì›ë°œ ë¶€ìœ„ì—ì„œ ë©€ë¦¬ ë–¨ì–´ì§„ ë‹¤ë¥¸ ì¥ê¸°ë¡œì˜ ì „ì´\n",
      "- **ì§„ë‹¨í™•ì •**: ë³‘ë¦¬í•™ì  ê²€ì‚¬ë¡œ í™•ì§„ëœ ê²½ìš°\n",
      "- **ë©´ì±…ê¸°ê°„**: ë³´í†µ ê³„ì•½ì¼ë¡œë¶€í„° 90ì¼ ì´í›„ ë³´ì¥\n",
      "\n",
      "### 3. **ë³´ì¥ ì œì™¸ì‚¬í•­**\n",
      "- ì›ë°œì•”ì˜ ì¬ë°œ\n",
      "- ì¸ì ‘ì¥ê¸°ë¡œì˜ ì§ì ‘ ì¹¨ìœ¤\n",
      "- ë¦¼í”„ì ˆ ì „ì´ë§Œ ìˆëŠ” ê²½ìš° (ì¼ë¶€ ìƒí’ˆ)\n",
      "- ë©´ì±…ê¸°ê°„ ë‚´ ì§„ë‹¨\n",
      "\n",
      "### 4. **ë³´í—˜ì‚¬ë³„ ì°¨ì´ì **\n",
      "- ë³´ì¥ê¸ˆì•¡: 1,000ë§Œì›~5,000ë§Œì› ìˆ˜ì¤€\n",
      "- ì„¸ë¶€ ì•½ê´€ ì¡°ê±´ ìƒì´\n",
      "- ê°±ì‹ /ë¹„ê°±ì‹  ì—¬ë¶€\n",
      "\n",
      "**ì •í™•í•œ ë³´ì¥ë²”ìœ„ëŠ” ê°€ì…í•˜ì‹  ë³´í—˜ìƒí’ˆì˜ ì•½ê´€ì„ í™•ì¸í•˜ì‹œê±°ë‚˜, ë³´í—˜ì‚¬ì— ì§ì ‘ ë¬¸ì˜í•˜ì‹œëŠ” ê²ƒì´ ê°€ì¥ ì •í™•í•©ë‹ˆë‹¤.**\n",
      "\n",
      "ğŸ“š [RAG ê¸°ë°˜ ì‘ë‹µ]:\n",
      "ì œê³µëœ ë¬¸ì„œì—ì„œ í†µí•©ì „ì´ì•”ì§„ë‹¨ë¹„ì˜ êµ¬ì²´ì ì¸ ë³´ì¥ ë²”ìœ„ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œì—ëŠ” \"í†µí•©ì „ì´ì•”ì§„ë‹¨ë¹„ã€ê°±ì‹ ê³„ì•½ã€‘\"ë¼ëŠ” í•­ëª©ì´ ì–¸ê¸‰ë˜ì–´ ìˆê³ , í†µí•©ì•”ì§„ë‹¨ë¹„â…¡(ì „ì´ì•”í¬í•¨)ì— ëŒ€í•œ ë‚´ìš©ì´ ì¼ë¶€ í¬í•¨ë˜ì–´ ìˆìœ¼ë‚˜, í†µí•©ì „ì´ì•”ì§„ë‹¨ë¹„ì˜ ì •í™•í•œ ë³´ì¥ ë²”ìœ„ëŠ” ëª…ì‹œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì •í™•í•œ ë³´ì¥ ë²”ìœ„ë¥¼ í™•ì¸í•˜ë ¤ë©´ í•´ë‹¹ ë³´í—˜ì•½ê´€ì˜ í†µí•©ì „ì´ì•”ì§„ë‹¨ë¹„ ì¡°í•­ì„ ì§ì ‘ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# âœ… 3. ì§ˆë¬¸ ì‹¤í–‰\n",
    "# ---------------------------------------------------\n",
    "# ì§ˆë¬¸\n",
    "# question = \"ê³ ì§€ì˜ë¬´ë¥¼ ìœ„ë°˜í•œ ê²½ìš° ë³´í—˜ì‚¬ëŠ” ì–´ë–¤ ì¡°ì¹˜ë¥¼ ì·¨í•  ìˆ˜ ìˆë‚˜ìš”?\"                                  # ë¯¼ì„ ì§ˆë¬¸\n",
    "# question = \"íŠ¹ì •ì•” iië€ ë­ì•¼?\"                                                                          # 1ë²ˆ ì§ˆë¬¸\n",
    "# question = \"ìœ ì‚¬ì•”ì§„ë‹¨ë¹„iii ë¥¼ ì²­êµ¬í•˜ë ¤ê³  í•˜ëŠ”ë° ê°‘ìƒì„ ì•”ì€ ì–´ë–¤ ê²€ì‚¬ë¥¼ í†µí•´ ì§„ë‹¨ë°›ì•„ì•¼ë¼?\"                # 2ë²ˆ ì§ˆë¬¸                                                   # 3ë²ˆ ì§ˆë¬¸\n",
    "question = \"í†µí•©ì „ì´ì•”ì§„ë‹¨ë¹„ì˜ ë³´ì¥ì˜ë²”ìœ„ëŠ” ì–´ë–»ê²Œ ë¼?\"                                                     # 4ë²ˆ ì§ˆë¬¸\n",
    "# question = \"ë³´í•¨ê³„ì•½í•œì§€ 8ê°œì›”ì´ ì§€ë‚¬ëŠ”ë° í‘œì í•­ì•”ë°©ì‚¬ì„  ì¹˜ë£Œë¹„ë¥¼ ë³´í—˜ê°€ì…ê¸ˆì•¡ì˜ 100%ë¥¼ ë°›ì„ ìˆ˜ ìˆì–´?\"      # 5ë²ˆ ì§ˆë¬¸\n",
    "# question = \"ì‹ ì¬ì§„ë‹¨ì•”ì§„ë‹¨ë¹„ii ì—ì„œ ìˆ˜ìˆ ì´ë€ ë­ì•¼?\"                                                       # 6ë²ˆ ì§ˆë¬¸    \n",
    "# question = \"ë³´í—˜ê¸ˆì²­êµ¬ í–ˆëŠ”ë° ì–¸ì œ ì§€ê¸‰ë˜ë‹ˆ?\"      \n",
    "\n",
    "\n",
    "# 1. RAG ê¸°ë°˜ ì‘ë‹µ\n",
    "rag_answer = rag_chain.invoke(question)\n",
    "\n",
    "# 2. LLM ë‹¨ë… ì‘ë‹µ\n",
    "llm_only_answer = llm_only_chain.invoke(question)\n",
    "\n",
    "# ì¶œë ¥\n",
    "print(\"ğŸ§¾ ì§ˆë¬¸:\", question)\n",
    "print(\"\\nğŸ’¬ [LLM ë‹¨ë… ì‘ë‹µ]:\")\n",
    "print(llm_only_answer)\n",
    "print(\"\\nğŸ“š [RAG ê¸°ë°˜ ì‘ë‹µ]:\")\n",
    "print(rag_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8d2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
